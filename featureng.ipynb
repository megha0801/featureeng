{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "->A parameter is a value that you pass into a function, method, or system to custommize its behavior or to provide it with the data it need to operate. It acts like a placeholder that gets its value when the function is called."
      ],
      "metadata": {
        "id": "_4y-qYeOYFBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation? What does negative correlation mean?\n",
        "\n",
        "-> Correlation is a statistical measure that describe the strength and direction of a relationship between two variables.\n",
        "\n",
        "-> Negative coreelation means that as one variables increases, the other decreases, and vice versa. They move in opposite directions.\n"
      ],
      "metadata": {
        "id": "wt9sNuuZY8DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "-> Machine Learning is a branch of artificial intelligence that allows systems to learn from data, imporve over time, and make decisions or predictions without being explicitly programmed for every task."
      ],
      "metadata": {
        "id": "d0lomK05ZY0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "-> The loss value shows how far a model's predictions are from the actual results. A low loss means better performance, while a high loss indicates poor predictions. It helps guide the model to improve during training by minimizing this error."
      ],
      "metadata": {
        "id": "OZnlbtT5aN9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "\n",
        "-> Continuous variables are numerical values that can take any value withinn a range. They are measurable and often include things like height, weight, temperature, or salary.\n",
        "\n",
        "-> Categorical variables are values that represent categories or groups. They describe qualities or labels, such as gender, color, or type of product."
      ],
      "metadata": {
        "id": "N26SUhlFa5fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "-> In machine learning, we can't feed raw categorical variables directly into models. They need to be converted into numerical format. This process is called encoding.\n",
        "\n",
        "-> Common techniques to handle categorical variables:\n",
        "\n",
        "1. Label encoding\n",
        "2. one-Hot encoding\n",
        "3. Ordinal encoding\n",
        "4. Frequency or count encoding\n",
        "5. Target encoding"
      ],
      "metadata": {
        "id": "H0eJsPeDbk7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "-> This is the process where the model learns from data. The training dataset contains input data along with the correct output, and the model uses this to learn patterns and relationship.\n",
        "\n",
        "->After training, the model is evaluated on a testing dataset, a separate set of data that the model has never seen before. This helps us check how well the model performs on new, unseen data, and whether it can generalize well."
      ],
      "metadata": {
        "id": "DNC1U2X8ck6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "-> sklearn.preprocessing is a module in scikit-learn that provides tools for data preprocessing. This module helps prepare and transform raw data into a format suitable for machine learning models.Preprocessing is essential because most machine learning models require data to be in a specific format, often scaled, encoded, or normalized."
      ],
      "metadata": {
        "id": "dwaFy_OSdfBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "\n",
        "-> A test set is a subset of the dataset that is used to evaluate the performance of a machine learning model after it has been trained. It consists of data that the model has never seen during training, and it is used to simulate how well the model will perform on new, unseen data in real-world scenario."
      ],
      "metadata": {
        "id": "o_BrafHTej7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "-> In python, the most common way to spilt your data for training and testing is using the train_test_split() function from sklearn.moel_selection.\n",
        "\n",
        "-> How to approach a machine learning problem:\n",
        "\n",
        "1. Define the problem\n",
        "2. Collect and prepare data\n",
        "3. Select a model\n",
        "4. Train the model\n",
        "5. Evaluate the model\n",
        "6. Fine-Tune the model\n",
        "7. Deploy and monitor"
      ],
      "metadata": {
        "id": "w0AKgalvfZ4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "-> Exploratory data analysis is a crucial step in the machine learning pipline because it helps you understand your data before fittiing a model. Performing EDA helps in identifying patterns, relationships, anomalies, and potential issues in the data that could affect model performance."
      ],
      "metadata": {
        "id": "A3W2o-wDgc_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "\n",
        "-> Correlationo is a statistival measure that describe the strength and direction of the relatioonship between two or more variables. It tells you whether, and how strongly, pairs of variables are related."
      ],
      "metadata": {
        "id": "i0AFHbCchG6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "\n",
        "-> Negative correlation means that as one variable increases, the other variable decreases, or vice versa. In other words, there is an inverse relationship between the two variables."
      ],
      "metadata": {
        "id": "J3_-jnAohmm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "\n",
        "-> To find the correlation between variables in python, you can use the pandas library, which provides a straightward way to calculate correlation between numerical columns in a dataframe."
      ],
      "metadata": {
        "id": "iwEPOElzicpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "-> Causation refers to a cause-and-effect relationship between two variables, where one variable directly causes the change on another variable. In other words, a change in one variable is responsible for bringing about a change in another variable.\n",
        "\n",
        "-> While correlation indicates that two variables have a statistical relationship, it does not imply that one causes the other. On the other hand, causation implies a direct cause-and-effect relationship."
      ],
      "metadata": {
        "id": "AFN5wLbFi_bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "-> In the cottext of machine learning and deep learning, an optimizer is an algorithem or method used to adjust the parameters of amodel to minimize the loss function during training. The goal is to make the moel predictions as accurate as possible by reducing the difference between predicted and actual outputs.\n",
        "\n",
        "-> Types of Optimizers:\n",
        "\n",
        "1. Gradient Descent: A basic optimizer that updates weights based on teh entire dataset.\n",
        "\n",
        "Example: Let's say you are training a model to predict house prices. If you use gradient descent, the algorithem will calculate the average gradient from all the data points before updating the weights.\n",
        "\n",
        "2. Stochastic gradient descent: Unlike regular GD, SGD updates weights using only one sample at atime, making it faster but noiser.\n",
        "\n",
        "Example: Useful when training with very large datasets (e.g., image rcognition with millions of photos).\n",
        "\n",
        "3. Mini-batch gradient descent: A mix between GD and SGD. It updates weights based on small batches of data.\n",
        "\n",
        "Example: If you have 10,000 data points, you might update weights every 100 samples (mini-batch size = 100)\n",
        "\n",
        "4. Momentum: Builds upon SGD by adding a fraction of the previous update to the current one. This helps accelerate the convergence and smooth the path.\n",
        "\n",
        "Example: Think of it like pushing a ball down a hill - it builds speed and moves faster in the same direction.\n",
        "\n",
        "5. AdaGrad: Adapts the learning rate for each parameter based on past gradients. It gives smaller learning rates to frequently updated parameters.\n",
        "\n",
        "Example: Used for sparse data (like NLP problems where only some words appear frequently).\n",
        "\n",
        "6. RMSprop: Fixes the problem of AdaGrad by using an exponential moviing average of squares gradients.\n",
        "\n",
        "Example: Popular in training recurrent neural networks.\n",
        "\n",
        "7. Adam: Combines the benefits of both Momentum and RMSprop\n",
        "\n",
        "Example: Widely used in image recognition, NLP, and most deep learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "FxnrMHu8kK0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "-> sksklearn.linear_model is a module in the scikit-learn library that contains linear models for regression and classification tasks.\n",
        "\n",
        "-> Scikit-learn is one of the most popular python libraries used in machine learning, and the linear_model module specifically deals with models that assume a linear relationship between the input variables and the output."
      ],
      "metadata": {
        "id": "F7CsAB4cd-kS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "-> The .fit() method in scikit-learn is used to train the model. It takes in input features(X) and target values(Y), and learns the relationship between them.\n",
        "\n",
        "-> Required arguments:\n",
        "\n",
        "1. X (features/input):\n",
        "\n",
        "* A 2D array or dataframe: shape = (n_samples, n_features)\n",
        "\n",
        "* Each row = one data point\n",
        "\n",
        "* Each column = one feature\n",
        "\n",
        "2. Y (target/output):\n",
        "\n",
        "* A 1D array or Series: shape = (n_samples)\n",
        "\n",
        "* Contains the output values or labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PF63TXkhe9i9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "->\n",
        "\n",
        "* Make predictions based on new data.\n",
        "\n",
        "* It returns the output values or class labels based on e=what the model has learned.\n",
        "\n",
        "-> X - input data:\n",
        "\n",
        "\n",
        "* A 2D array or dataframe\n",
        "\n",
        "* Each row = one data point you want to make a prediction for.\n",
        "\n",
        "* Should have the same number of features as the training data\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-hxSAGmSgyHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What are continuous and categorical variables?\n",
        "\n",
        "-> Continuous variables: Continuous variables are numerical values that can take any value within a range including decimals.\n",
        "\n",
        "-> Categorical: Categorical variables represent groups or categories. They describe qualities or characteristics."
      ],
      "metadata": {
        "id": "_Gwobixyhtiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "-> Feature scaling is the process of normalizing or standardizing the range of independent variables so that they are on a similar scale.\n",
        "\n",
        "-> How does it hrlp in machine learning:\n",
        "\n",
        "1. Faster convergence\n",
        "2. Better accuracy\n",
        "3. Removes bias\n",
        "4. Improves clustering"
      ],
      "metadata": {
        "id": "88ZqBoH2ijWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "\n",
        "->\n",
        "1. Standardization\n",
        "2. Min-Max scaling\n",
        "3. Robust Scaling   "
      ],
      "metadata": {
        "id": "0daiihr4jRlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "-> sklearn.preprocessing is a module in the scikit-learn library that provides tools to prepare or trasform your data before feeding it into a machine learning model."
      ],
      "metadata": {
        "id": "8pvBlp2Vj3N0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "->"
      ],
      "metadata": {
        "id": "c4g1oO7gkQYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "U8VTxHg9kc0C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = {\n",
        "    'Experience': [1, 2, 3, 4, 5],\n",
        "    'Salary': [30000, 35000, 40000, 45000, 50000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(X_train)\n",
        "print(\"\\nTesting Set:\")\n",
        "print(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPBqscgXkp0i",
        "outputId": "5f184542-ef6f-4c70-8222-8094adcb3dc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set:\n",
            "   Experience\n",
            "0           1\n",
            "1           2\n",
            "3           4\n",
            "4           5\n",
            "\n",
            "Testing Set:\n",
            "   Experience\n",
            "2           3\n"
          ]
        }
      ]
    }
  ]
}